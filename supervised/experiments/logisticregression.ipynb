{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV,  ParameterGrid, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, classification_report\n",
    ")\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import joblib\n",
    "\n",
    "from utils.data_utils import process_data_for_lr\n",
    "from utils.evaluation import evaluate_model\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "logger = logging.getLogger('LogisticRegression')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, num_rows=None):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df.sample(n=num_rows, random_state=42) if num_rows else df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lr(X_train, y_train, cv_folds=5, param_grid=None):\n",
    "    \"\"\"\n",
    "    Train a Logistic Regression model using k-fold cross-validation with hyperparameter tuning.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training features (DataFrame or array)\n",
    "    - y_train: Training labels (Series or array)\n",
    "    - cv_folds: Number of folds for cross-validation.\n",
    "    - param_grid: Dictionary of hyperparameters to search over.\n",
    "\n",
    "    Returns:\n",
    "    - best_model: The best Logistic Regression model found via GridSearchCV.\n",
    "    - grid_search: The fitted GridSearchCV object (for further inspection if needed).\n",
    "    \"\"\"\n",
    "    # Set default hyperparameter grid if not provided\n",
    "    if param_grid is None:\n",
    "        # Define separate parameter grids for different solvers to ensure compatibility\n",
    "        param_grid = [\n",
    "            # liblinear solver - works with l1 and l2 penalties\n",
    "            {\n",
    "                'solver': ['liblinear'],\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "                'max_iter': [100, 500, 1000]\n",
    "            },\n",
    "            # lbfgs solver - only works with l2 penalty\n",
    "            {\n",
    "                'solver': ['lbfgs'],\n",
    "                'penalty': ['l2'],\n",
    "                'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "                'max_iter': [100, 500, 1000]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "    # Initialize the logistic regression classifier\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "\n",
    "    # Setup k-fold cross-validation\n",
    "    kfold = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize GridSearchCV for hyperparameter tuning\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=param_grid,\n",
    "        cv=kfold,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        refit=True,  # refit on the entire training set with the best params\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Fit grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best parameters found:\", best_params)\n",
    "    print(\"Best cross-validation accuracy: {:.4f}\".format(grid_search.best_score_))\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    return best_model, grid_search, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "Best parameters found: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best cross-validation accuracy: 0.7467\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Logistic Regression Evaluation Results\n",
       "\n",
       "## Metrics\n",
       "\n",
       "| Metric                    | Score    |\n",
       "|---------------------------|----------|\n",
       "| Validation Accuracy       | 0.7400 |\n",
       "| Validation F1 Score (weighted) | 0.7344 |\n",
       "| Validation Precision (weighted) | 0.7346 |\n",
       "| Validation Recall (class 1) | 0.5676 |\n",
       "| Binary Precision (class 1) | 0.6774 |\n",
       "| Binary F1 Score (class 1) | 0.6176 |\n",
       "| ROC-AUC Score             | 0.8130 |\n",
       "\n",
       "## Detailed Classification Report\n",
       "\n",
       "```\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           0       0.77      0.84      0.80        63\n",
       "           1       0.68      0.57      0.62        37\n",
       "\n",
       "    accuracy                           0.74       100\n",
       "   macro avg       0.72      0.70      0.71       100\n",
       "weighted avg       0.73      0.74      0.73       100\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "df_1000 = load_data('../data/train.csv', num_rows=1000)\n",
    "\n",
    "# Process data\n",
    "lr_obj = process_data_for_lr(df_1000, mode='train')\n",
    "\n",
    "X = lr_obj['X']\n",
    "y = lr_obj['y']\n",
    "feature_names = lr_obj['feature_names']\n",
    "preprocessor = lr_obj['preprocessor']\n",
    "scaler = preprocessor['scaler']\n",
    "encoder = preprocessor['encoder']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "best_model, grid_search, best_params = tune_lr(X_train, y_train, cv_folds=5)\n",
    "\n",
    "y_predictions = best_model.predict(X_test)\n",
    "y_probabilities = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "lr_metrics, lr_markdown = evaluate_model(\n",
    "    y_test,\n",
    "    y_predictions,\n",
    "    y_probabilities,\n",
    "    model_name=\"Logistic Regression\"\n",
    ")\n",
    "\n",
    "display(Markdown(lr_markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(X, y):\n",
    "  \"\"\"Undersample to match classes 1:1\"\"\"\n",
    "  sampler = RandomUnderSampler(random_state=42)\n",
    "  X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "  logger.info('Class distribution before sampling: %s', np.bincount(y))\n",
    "  logger.info('Class distribution after sampling: %s', np.bincount(y_resampled))\n",
    "  return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Logistic Regression Evaluation Results\n",
       "\n",
       "## Metrics\n",
       "\n",
       "| Metric                    | Score    |\n",
       "|---------------------------|----------|\n",
       "| Validation Accuracy       | 0.7276 |\n",
       "| Validation F1 Score (weighted) | 0.7298 |\n",
       "| Validation Precision (weighted) | 0.7353 |\n",
       "| Validation Recall (class 1) | 0.7136 |\n",
       "| Binary Precision (class 1) | 0.6363 |\n",
       "| Binary F1 Score (class 1) | 0.6727 |\n",
       "| ROC-AUC Score             | 0.8029 |\n",
       "\n",
       "## Detailed Classification Report\n",
       "\n",
       "```\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           0       0.80      0.74      0.77     24933\n",
       "           1       0.64      0.71      0.67     16100\n",
       "\n",
       "    accuracy                           0.73     41033\n",
       "   macro avg       0.72      0.73      0.72     41033\n",
       "weighted avg       0.74      0.73      0.73     41033\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resample_flag = True\n",
    "drop_features_flag = True\n",
    "\n",
    "# Load data\n",
    "df_full = load_data('../data/train.csv')\n",
    "\n",
    "# Process data\n",
    "lr_obj = process_data_for_lr(df_full, mode='train')\n",
    "\n",
    "X = lr_obj['X']\n",
    "y = lr_obj['y']\n",
    "feature_names = lr_obj['feature_names']\n",
    "preprocessor = lr_obj['preprocessor']\n",
    "scaler = preprocessor['scaler']\n",
    "encoder = preprocessor['encoder']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "if resample_flag:\n",
    "    X_train, y_train = resample(X_train, y_train)\n",
    "    best_params.setdefault('class_weight', 'balanced')\n",
    "\n",
    "lr_model = LogisticRegression(**best_params)\n",
    "lr_model.fit(X, y)\n",
    "\n",
    "y_predictions = lr_model.predict(X_test)\n",
    "y_probabilities = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "lr_metrics, lr_markdown = evaluate_model(\n",
    "    y_test,\n",
    "    y_predictions,\n",
    "    y_probabilities,\n",
    "    model_name=\"Logistic Regression\"\n",
    ")\n",
    "\n",
    "\n",
    "# dump scaler and encoder\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(lr_model, \"models/logistic_regression_model.pkl\")\n",
    "joblib.dump(scaler, \"models/lr_scaler.pkl\")\n",
    "joblib.dump(encoder, \"models/lr_encoder.pkl\")\n",
    "joblib.dump(preprocessor, \"models/lr_preprocessor.pkl\")\n",
    "\n",
    "display(Markdown(lr_markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "val_df = pd.read_csv('../data/validation.csv')\n",
    "\n",
    "# Process validation data\n",
    "lr_obj_test = process_data_for_lr(val_df, preprocessor=preprocessor, mode='inference')\n",
    "lr_X = lr_obj['X']\n",
    "lr_y = lr_obj['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_y_predictions = lr_model.predict(lr_X)\n",
    "lr_y_probabilities = lr_model.predict_proba(lr_X)[:, 1]\n",
    "# For Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Logistic Regression Evaluation Results\n",
       "\n",
       "## Metrics\n",
       "\n",
       "| Metric                    | Score    |\n",
       "|---------------------------|----------|\n",
       "| Validation Accuracy       | 0.7267 |\n",
       "| Validation F1 Score (weighted) | 0.7289 |\n",
       "| Validation Precision (weighted) | 0.7343 |\n",
       "| Validation Recall (class 1) | 0.7115 |\n",
       "| Binary Precision (class 1) | 0.6355 |\n",
       "| Binary F1 Score (class 1) | 0.6714 |\n",
       "| ROC-AUC Score             | 0.8022 |\n",
       "\n",
       "## Detailed Classification Report\n",
       "\n",
       "```\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           0       0.80      0.74      0.77    249302\n",
       "           1       0.64      0.71      0.67    161024\n",
       "\n",
       "    accuracy                           0.73    410326\n",
       "   macro avg       0.72      0.72      0.72    410326\n",
       "weighted avg       0.73      0.73      0.73    410326\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_metrics, lr_markdown = evaluate_model(\n",
    "    lr_y,\n",
    "    lr_y_predictions,\n",
    "    y_prob=lr_y_probabilities,\n",
    "    model_name=\"Logistic Regression\"\n",
    ")\n",
    "\n",
    "display(Markdown(lr_markdown))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model demonstrates moderate and balanced performance on the validation set. With an accuracy of 73.3%, the model correctly classifies roughly three out of every four instances. Precision (73.0%) and recall (73.3%) indicate that the model maintains a consistent ability to identify positive cases while minimizing false positives. The F1 score of 72.8% reinforces this balance, while a ROC AUC of 0.790 shows that the model has a fair ability to discriminate between classes. Overall, these results justify the decision to adopt this final model for the problem at hand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
